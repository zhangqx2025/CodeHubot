#!/usr/bin/env python3
"""
æŸ¥çœ‹å‘é‡æ•°æ®çš„è„šæœ¬
"""
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from app.core.database import SessionLocal
from app.models.document import Document, DocumentChunk
from app.models.knowledge_base import KnowledgeBase
from sqlalchemy import func


def check_vectors():
    """æ£€æŸ¥å‘é‡æ•°æ®"""
    db = SessionLocal()
    
    try:
        print("=" * 80)
        print("ğŸ“Š å‘é‡æ•°æ®æ£€æŸ¥æŠ¥å‘Š")
        print("=" * 80)
        
        # 1. ç»Ÿè®¡å·²å®Œæˆçš„æ–‡æ¡£
        completed_docs = db.query(Document).filter(
            Document.embedding_status == 'completed',
            Document.deleted_at.is_(None)
        ).all()
        
        print(f"\nâœ… å·²å®Œæˆå‘é‡åŒ–çš„æ–‡æ¡£: {len(completed_docs)} ä¸ª\n")
        
        if not completed_docs:
            print("âš ï¸  æ²¡æœ‰å·²å®Œæˆå‘é‡åŒ–çš„æ–‡æ¡£")
            return
        
        # 2. æ˜¾ç¤ºæ¯ä¸ªæ–‡æ¡£çš„è¯¦æƒ…
        for doc in completed_docs:
            print(f"ğŸ“„ æ–‡æ¡£ [{doc.id}] {doc.title}")
            print(f"   çŠ¶æ€: {doc.embedding_status}")
            print(f"   æ–‡æœ¬å—æ•°é‡: {doc.chunk_count}")
            print(f"   å‘é‡åŒ–æ—¶é—´: {doc.embedded_at}")
            
            # æŸ¥è¯¢è¯¥æ–‡æ¡£çš„æ–‡æœ¬å—
            chunks = db.query(DocumentChunk).filter(
                DocumentChunk.document_id == doc.id
            ).order_by(DocumentChunk.chunk_index).all()
            
            print(f"   å®é™…æ–‡æœ¬å—: {len(chunks)} ä¸ª")
            
            # ç»Ÿè®¡æœ‰å‘é‡çš„æ–‡æœ¬å—
            chunks_with_vector = sum(1 for c in chunks if c.embedding_vector)
            print(f"   æœ‰å‘é‡çš„å—: {chunks_with_vector} ä¸ª")
            
            if chunks:
                # æ˜¾ç¤ºç¬¬ä¸€ä¸ªæ–‡æœ¬å—çš„ä¿¡æ¯
                first_chunk = chunks[0]
                print(f"\n   ğŸ“ æ–‡æœ¬å— #0 ç¤ºä¾‹:")
                print(f"      å†…å®¹ï¼ˆå‰100å­—ï¼‰: {first_chunk.content[:100]}...")
                print(f"      å­—ç¬¦æ•°: {first_chunk.char_count}")
                print(f"      Tokenæ•°: {first_chunk.token_count}")
                
                if first_chunk.embedding_vector:
                    vector = first_chunk.embedding_vector
                    if isinstance(vector, list):
                        print(f"      âœ… å‘é‡ç»´åº¦: {len(vector)}")
                        print(f"      å‘é‡å‰5ç»´: {vector[:5]}")
                    else:
                        print(f"      âš ï¸  å‘é‡æ ¼å¼å¼‚å¸¸: {type(vector)}")
                else:
                    print(f"      âŒ æ— å‘é‡æ•°æ®")
            
            print()
        
        # 3. å…¨å±€ç»Ÿè®¡
        print("=" * 80)
        print("ğŸ“ˆ å…¨å±€ç»Ÿè®¡")
        print("=" * 80)
        
        total_docs = db.query(Document).filter(Document.deleted_at.is_(None)).count()
        total_chunks = db.query(DocumentChunk).count()
        chunks_with_vector = db.query(DocumentChunk).filter(
            DocumentChunk.embedding_vector.isnot(None)
        ).count()
        
        print(f"\næ€»æ–‡æ¡£æ•°: {total_docs}")
        print(f"æ€»æ–‡æœ¬å—æ•°: {total_chunks}")
        print(f"æœ‰å‘é‡çš„æ–‡æœ¬å—: {chunks_with_vector}")
        if total_chunks > 0:
            print(f"å‘é‡åŒ–ç‡: {chunks_with_vector * 100.0 / total_chunks:.2f}%")
        
        # 4. æŒ‰çŸ¥è¯†åº“ç»Ÿè®¡
        print("\n" + "=" * 80)
        print("ğŸ“š æŒ‰çŸ¥è¯†åº“ç»Ÿè®¡")
        print("=" * 80 + "\n")
        
        kbs = db.query(KnowledgeBase).filter(KnowledgeBase.deleted_at.is_(None)).all()
        
        for kb in kbs:
            doc_count = db.query(Document).filter(
                Document.knowledge_base_id == kb.id,
                Document.deleted_at.is_(None)
            ).count()
            
            completed_count = db.query(Document).filter(
                Document.knowledge_base_id == kb.id,
                Document.embedding_status == 'completed',
                Document.deleted_at.is_(None)
            ).count()
            
            chunk_count = db.query(DocumentChunk).filter(
                DocumentChunk.knowledge_base_id == kb.id
            ).count()
            
            print(f"ğŸ“š {kb.name}")
            print(f"   æ–‡æ¡£æ•°: {doc_count} (å·²å®Œæˆ: {completed_count})")
            print(f"   æ–‡æœ¬å—æ•°: {chunk_count}")
            print()
        
        print("=" * 80)
        print("âœ… æ£€æŸ¥å®Œæˆ")
        print("=" * 80)
        
    finally:
        db.close()


def show_chunk_detail(chunk_id: int):
    """æ˜¾ç¤ºç‰¹å®šæ–‡æœ¬å—çš„è¯¦ç»†ä¿¡æ¯"""
    db = SessionLocal()
    
    try:
        chunk = db.query(DocumentChunk).filter(DocumentChunk.id == chunk_id).first()
        
        if not chunk:
            print(f"âŒ æ–‡æœ¬å— {chunk_id} ä¸å­˜åœ¨")
            return
        
        print("=" * 80)
        print(f"ğŸ“ æ–‡æœ¬å—è¯¦æƒ… [ID: {chunk_id}]")
        print("=" * 80)
        
        print(f"\næ–‡æ¡£ID: {chunk.document_id}")
        print(f"çŸ¥è¯†åº“ID: {chunk.knowledge_base_id}")
        print(f"å—ç´¢å¼•: {chunk.chunk_index}")
        print(f"å­—ç¬¦æ•°: {chunk.char_count}")
        print(f"Tokenæ•°: {chunk.token_count}")
        
        print(f"\nå†…å®¹:")
        print("-" * 80)
        print(chunk.content)
        print("-" * 80)
        
        if chunk.embedding_vector:
            vector = chunk.embedding_vector
            if isinstance(vector, list):
                print(f"\nâœ… å‘é‡ç»´åº¦: {len(vector)}")
                print(f"å‘é‡ç±»å‹: {type(vector[0]) if vector else 'N/A'}")
                print(f"\nå‘é‡æ•°æ®ï¼ˆå‰10ç»´ï¼‰:")
                print(vector[:10])
                print(f"\nå‘é‡æ•°æ®ï¼ˆå10ç»´ï¼‰:")
                print(vector[-10:])
            else:
                print(f"\nâš ï¸  å‘é‡æ ¼å¼å¼‚å¸¸: {type(vector)}")
        else:
            print(f"\nâŒ æ— å‘é‡æ•°æ®")
        
        print("\n" + "=" * 80)
        
    finally:
        db.close()


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) > 1:
        # æ˜¾ç¤ºç‰¹å®šæ–‡æœ¬å—çš„è¯¦æƒ…
        try:
            chunk_id = int(sys.argv[1])
            show_chunk_detail(chunk_id)
        except ValueError:
            print("âŒ æ— æ•ˆçš„æ–‡æœ¬å—ID")
    else:
        # æ˜¾ç¤ºæ€»è§ˆ
        check_vectors()


if __name__ == '__main__':
    main()

