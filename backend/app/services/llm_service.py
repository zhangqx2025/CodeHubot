"""
å¤§æ¨¡å‹è°ƒç”¨æœåŠ¡
æ”¯æŒå¤šç§å›½äº§å’Œå›½é™…å¤§æ¨¡å‹
"""

import json
import requests
import logging
from typing import List, Dict, Any, Optional
from app.models.llm_model import LLMModel

logger = logging.getLogger(__name__)


class LLMService:
    """å¤§æ¨¡å‹è°ƒç”¨æœåŠ¡åŸºç±»"""
    
    def __init__(self, model: LLMModel):
        self.model = model
        self.api_base = model.api_base
        self.api_key = model.api_key
        self.model_name = model.name
        self.temperature = float(model.temperature) if model.temperature else 0.7
        self.max_tokens = model.max_tokens or 4096
        self.top_p = float(model.top_p) if model.top_p else 0.9
    
    def _log_request_details(self, provider: str, url: str, payload: Dict, functions: Optional[List[Dict]] = None):
        """ç»Ÿä¸€çš„è¯·æ±‚æ—¥å¿—è¾“å‡º"""
        logger.info("=" * 80)
        logger.info(f"ğŸ¤– è°ƒç”¨å¤§æ¨¡å‹ API - {provider}")
        logger.info("=" * 80)
        logger.info(f"ğŸ“ URL: {url}")
        logger.info(f"ğŸ·ï¸  Provider: {provider}")
        logger.info(f"ğŸ¯ Model: {self.model_name}")
        
        # API Key (è„±æ•æ˜¾ç¤º)
        masked_key = f"{self.api_key[:10]}...{self.api_key[-4:]}" if self.api_key and len(self.api_key) > 14 else "***"
        logger.info(f"ğŸ”‘ API Key: {masked_key}")
        
        # å‚æ•°é…ç½®
        logger.info(f"âš™ï¸  Temperature: {payload.get('temperature', self.temperature)}")
        logger.info(f"âš™ï¸  Max Tokens: {payload.get('max_tokens', self.max_tokens)}")
        logger.info(f"âš™ï¸  Top P: {payload.get('top_p', self.top_p)}")
        
        # æ¶ˆæ¯å†…å®¹
        messages = payload.get('messages', [])
        logger.info(f"ğŸ’¬ Messages Count: {len(messages)}")
        logger.info("ğŸ“ Messages Detail:")
        for i, msg in enumerate(messages, 1):
            role = msg.get('role', 'unknown')
            content = msg.get('content', '') or ''  # ç¡®ä¿ä¸ä¸º None
            # å®‰å…¨å¤„ç† content
            if content:
                content_preview = content[:200] + '...' if len(content) > 200 else content
            else:
                content_preview = '[ç©ºå†…å®¹]'
            logger.info(f"   [{i}] Role: {role}")
            logger.info(f"       Content: {content_preview}")
        
        # Functions (å·¥å…·)
        if functions:
            logger.info(f"ğŸ”§ Functions/Tools: {len(functions)} ä¸ª")
            logger.info("ğŸ“‹ Functions Detail:")
            for i, func in enumerate(functions, 1):
                func_name = func.get('name', 'unknown') or 'unknown'
                func_desc = func.get('description', 'N/A') or 'N/A'
                logger.info(f"   [{i}] {func_name}: {func_desc}")
                
                # æ‰“å°å‚æ•°å®šä¹‰
                if 'parameters' in func:
                    params = func['parameters']
                    if 'properties' in params:
                        logger.info(f"       å‚æ•°:")
                        for param_name, param_def in params['properties'].items():
                            param_type = param_def.get('type', 'unknown') or 'unknown'
                            param_desc = param_def.get('description', 'N/A') or 'N/A'
                            required = 'å¿…å¡«' if param_name in params.get('required', []) else 'å¯é€‰'
                            logger.info(f"         - {param_name} ({param_type}, {required}): {param_desc}")
            
            # Tool choice
            if 'tool_choice' in payload:
                logger.info(f"ğŸ¯ Tool Choice: {payload['tool_choice']}")
            elif 'function_call' in payload:
                logger.info(f"ğŸ¯ Function Call: {payload['function_call']}")
        else:
            logger.info("ğŸ”§ Functions/Tools: æ— ")
        
        # å®Œæ•´ Payload (JSON æ ¼å¼)
        logger.info("ğŸ“¦ å®Œæ•´è¯·æ±‚ Payload:")
        try:
            payload_json = json.dumps(payload, ensure_ascii=False, indent=2)
            logger.info(payload_json)
        except Exception as e:
            logger.error(f"   æ— æ³•åºåˆ—åŒ– payload: {e}")
        
        logger.info("=" * 80)
    
    def chat(
        self,
        messages: List[Dict[str, str]],
        functions: Optional[List[Dict[str, Any]]] = None,
        function_call: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        å‘é€èŠå¤©è¯·æ±‚åˆ°å¤§æ¨¡å‹
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨ [{"role": "user/assistant/system", "content": "..."}]
            functions: å¯ç”¨çš„å‡½æ•°åˆ—è¡¨ï¼ˆç”¨äº Function Callingï¼‰
            function_call: æ˜¯å¦å¼ºåˆ¶è°ƒç”¨å‡½æ•° ("auto", "none", {"name": "function_name"})
        
        Returns:
            {"response": "å›å¤å†…å®¹", "function_call": {...}}
        """
        provider = self.model.provider.lower()
        
        if provider == 'openai':
            return self._call_openai_api(messages, functions, function_call)
        elif provider == 'qwen':
            return self._call_qwen_api(messages, functions, function_call)
        elif provider == 'wenxin':
            return self._call_wenxin_api(messages, functions, function_call)
        elif provider == 'spark':
            return self._call_spark_api(messages, functions, function_call)
        elif provider == 'zhipu':
            return self._call_zhipu_api(messages, functions, function_call)
        elif provider == 'moonshot':
            return self._call_moonshot_api(messages, functions, function_call)
        elif provider == 'deepseek':
            return self._call_deepseek_api(messages, functions, function_call)
        elif provider == 'doubao':
            return self._call_doubao_api(messages, functions, function_call)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹æä¾›å•†: {provider}")
    
    def _call_openai_api(
        self,
        messages: List[Dict[str, str]],
        functions: Optional[List[Dict[str, Any]]] = None,
        function_call: Optional[str] = None
    ) -> Dict[str, Any]:
        """è°ƒç”¨ OpenAI API"""
        url = f"{self.api_base}/chat/completions"
        
        payload = {
            "model": self.model_name,
            "messages": messages,
            "temperature": float(self.temperature) if self.temperature else 0.7,
            "max_tokens": int(self.max_tokens) if self.max_tokens else 2000,
            "top_p": float(self.top_p) if self.top_p else 0.9
        }
        
        if functions:
            payload["functions"] = functions
            payload["function_call"] = function_call or "auto"
        
        # æ‰“å°è¯¦ç»†è¯·æ±‚æ—¥å¿—
        self._log_request_details("OpenAI", url, payload, functions)
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        response = requests.post(url, json=payload, headers=headers, timeout=60)
        
        # æ‰“å°å“åº”çŠ¶æ€
        logger.info(f"ğŸ“¡ å“åº”çŠ¶æ€ç : {response.status_code}")
        if response.status_code != 200:
            logger.error(f"âŒ API è°ƒç”¨å¤±è´¥: {response.text}")
        
        response.raise_for_status()
        
        result = response.json()
        choice = result["choices"][0]
        message = choice["message"]
        
        output = {}
        if message.get("content"):
            output["response"] = message["content"]
            logger.info(f"âœ… å“åº”å†…å®¹: {message['content'][:200]}...")
        if message.get("function_call"):
            output["function_call"] = {
                "name": message["function_call"]["name"],
                "arguments": json.loads(message["function_call"]["arguments"])
            }
            logger.info(f"ğŸ”§ Function Call: {message['function_call']['name']}")
            logger.info(f"ğŸ“ Arguments: {json.dumps(output['function_call']['arguments'], ensure_ascii=False)}")
        
        return output
    
    def _call_qwen_api(
        self,
        messages: List[Dict[str, str]],
        functions: Optional[List[Dict[str, Any]]] = None,
        function_call: Optional[str] = None
    ) -> Dict[str, Any]:
        """è°ƒç”¨é˜¿é‡Œé€šä¹‰åƒé—® APIï¼ˆå…¼å®¹ OpenAI æ ¼å¼ï¼‰"""
        # é€šä¹‰åƒé—®ä½¿ç”¨ DashScope SDKï¼Œè¿™é‡Œä½¿ç”¨ OpenAI å…¼å®¹æ¥å£
        api_base = self.api_base or 'https://dashscope.aliyuncs.com/compatible-mode/v1'
        url = f"{api_base}/chat/completions"
        
        payload = {
            "model": self.model_name,
            "messages": messages,
            "temperature": float(self.temperature) if self.temperature else 0.7,
            "max_tokens": int(self.max_tokens) if self.max_tokens else 2000,
            "top_p": float(self.top_p) if self.top_p else 0.9
        }
        
        if functions:
            # é€šä¹‰åƒé—®æ”¯æŒ Function Calling
            payload["tools"] = [{"type": "function", "function": func} for func in functions]
            if function_call and function_call != "none":
                payload["tool_choice"] = "auto"
        
        # æ‰“å°è¯¦ç»†è¯·æ±‚æ—¥å¿—
        self._log_request_details("Qwen (é€šä¹‰åƒé—®)", url, payload, functions)
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        response = requests.post(url, json=payload, headers=headers, timeout=60)
        
        # æ‰“å°å“åº”çŠ¶æ€
        logger.info(f"ğŸ“¡ å“åº”çŠ¶æ€ç : {response.status_code}")
        if response.status_code != 200:
            logger.error(f"âŒ API è°ƒç”¨å¤±è´¥: {response.text}")
        
        response.raise_for_status()
        
        result = response.json()
        choice = result["choices"][0]
        message = choice["message"]
        
        output = {}
        if message.get("content"):
            output["response"] = message["content"]
            logger.info(f"âœ… å“åº”å†…å®¹: {message['content'][:200]}...")
        
        # æ·»åŠ  token ä½¿ç”¨é‡ä¿¡æ¯
        if "usage" in result:
            output["usage"] = result["usage"]
            logger.info(f"ğŸ“Š Tokenä½¿ç”¨: {json.dumps(result['usage'], ensure_ascii=False)}")
        
        if message.get("tool_calls"):
            # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            tool_call = message["tool_calls"][0]
            output["function_call"] = {
                "name": tool_call["function"]["name"],
                "arguments": json.loads(tool_call["function"]["arguments"])
            }
            logger.info(f"ğŸ”§ Tool Call: {tool_call['function']['name']}")
            logger.info(f"ğŸ“ Arguments: {json.dumps(output['function_call']['arguments'], ensure_ascii=False)}")
        
        return output
    
    def _call_wenxin_api(
        self,
        messages: List[Dict[str, str]],
        functions: Optional[List[Dict[str, Any]]] = None,
        function_call: Optional[str] = None
    ) -> Dict[str, Any]:
        """è°ƒç”¨ç™¾åº¦æ–‡å¿ƒä¸€è¨€ API"""
        # æ–‡å¿ƒä¸€è¨€éœ€è¦å…ˆè·å– access_token
        # ç®€åŒ–å®ç°ï¼šå‡è®¾ api_key æ˜¯ access_token
        url = f"{self.api_base or 'https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat'}/{self.model_name}"
        
        payload = {
            "messages": messages,
            "temperature": float(self.temperature) if self.temperature else 0.7,
            "top_p": float(self.top_p) if self.top_p else 0.9
        }
        
        if functions:
            payload["functions"] = functions
        
        params = {"access_token": self.api_key}
        
        response = requests.post(url, json=payload, params=params, timeout=60)
        response.raise_for_status()
        
        result = response.json()
        
        output = {"response": result.get("result", "")}
        
        if result.get("function_call"):
            output["function_call"] = {
                "name": result["function_call"]["name"],
                "arguments": json.loads(result["function_call"]["arguments"])
            }
        
        return output
    
    def _call_spark_api(
        self,
        messages: List[Dict[str, str]],
        functions: Optional[List[Dict[str, Any]]] = None,
        function_call: Optional[str] = None
    ) -> Dict[str, Any]:
        """è°ƒç”¨è®¯é£æ˜Ÿç« API"""
        # æ˜Ÿç«è®¤çŸ¥å¤§æ¨¡å‹éœ€è¦ WebSocket è¿æ¥ï¼Œè¿™é‡Œç®€åŒ–å®ç°
        # å®é™…ä½¿ç”¨åº”è¯¥ä½¿ç”¨å®˜æ–¹ SDK
        raise NotImplementedError("è®¯é£æ˜Ÿç« API éœ€è¦ä½¿ç”¨ WebSocketï¼Œè¯·ä½¿ç”¨å®˜æ–¹ SDK")
    
    def _call_zhipu_api(
        self,
        messages: List[Dict[str, str]],
        functions: Optional[List[Dict[str, Any]]] = None,
        function_call: Optional[str] = None
    ) -> Dict[str, Any]:
        """è°ƒç”¨æ™ºè°± GLM APIï¼ˆå…¼å®¹ OpenAI æ ¼å¼ï¼‰"""
        url = f"{self.api_base or 'https://open.bigmodel.cn/api/paas/v4'}/chat/completions"
        
        payload = {
            "model": self.model_name,
            "messages": messages,
            "temperature": float(self.temperature) if self.temperature else 0.7,
            "max_tokens": int(self.max_tokens) if self.max_tokens else 2000,
            "top_p": float(self.top_p) if self.top_p else 0.9
        }
        
        if functions:
            payload["tools"] = [{"type": "function", "function": func} for func in functions]
            if function_call and function_call != "none":
                payload["tool_choice"] = "auto"
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        response = requests.post(url, json=payload, headers=headers, timeout=60)
        response.raise_for_status()
        
        result = response.json()
        choice = result["choices"][0]
        message = choice["message"]
        
        output = {}
        if message.get("content"):
            output["response"] = message["content"]
        if message.get("tool_calls"):
            tool_call = message["tool_calls"][0]
            output["function_call"] = {
                "name": tool_call["function"]["name"],
                "arguments": json.loads(tool_call["function"]["arguments"])
            }
        
        return output
    
    def _call_moonshot_api(
        self,
        messages: List[Dict[str, str]],
        functions: Optional[List[Dict[str, Any]]] = None,
        function_call: Optional[str] = None
    ) -> Dict[str, Any]:
        """è°ƒç”¨æœˆä¹‹æš—é¢ Kimi APIï¼ˆå…¼å®¹ OpenAI æ ¼å¼ï¼‰"""
        return self._call_openai_api(messages, functions, function_call)
    
    def _call_deepseek_api(
        self,
        messages: List[Dict[str, str]],
        functions: Optional[List[Dict[str, Any]]] = None,
        function_call: Optional[str] = None
    ) -> Dict[str, Any]:
        """è°ƒç”¨ DeepSeek APIï¼ˆå…¼å®¹ OpenAI æ ¼å¼ï¼‰"""
        return self._call_openai_api(messages, functions, function_call)
    
    def _call_doubao_api(
        self,
        messages: List[Dict[str, str]],
        functions: Optional[List[Dict[str, Any]]] = None,
        function_call: Optional[str] = None
    ) -> Dict[str, Any]:
        """è°ƒç”¨ç«å±±å¼•æ“è±†åŒ… APIï¼ˆOpenAI å…¼å®¹æ¥å£ï¼‰"""
        # ç«å±±å¼•æ“æ–¹èˆŸå¹³å°ä½¿ç”¨ OpenAI å…¼å®¹çš„ API
        # API Base: https://ark.cn-beijing.volces.com/api/v3
        # å®Œæ•´è·¯å¾„: https://ark.cn-beijing.volces.com/api/v3/chat/completions
        
        api_base = self.model.api_base or 'https://ark.cn-beijing.volces.com/api/v3'
        
        # ç»Ÿä¸€å¤„ç† API Baseï¼Œç¡®ä¿æ²¡æœ‰å°¾éƒ¨æ–œæ 
        api_base = api_base.rstrip('/')
        
        # æ„å»ºå®Œæ•´ URL
        url = f"{api_base}/chat/completions"
        
        payload = {
            "model": self.model.name,
            "messages": messages,
            "temperature": float(self.model.temperature) if self.model.temperature else 0.7,
            "max_tokens": int(self.model.max_tokens) if self.model.max_tokens else 2000,
            "top_p": float(self.model.top_p) if self.model.top_p else 0.9
        }
        
        if functions:
            # è±†åŒ…æ”¯æŒ Function Callingï¼Œä½¿ç”¨ tools æ ¼å¼ï¼ˆOpenAI æ–°æ ¼å¼ï¼‰
            payload["tools"] = [{"type": "function", "function": func} for func in functions]
            if function_call and function_call != "none":
                payload["tool_choice"] = "auto"
        
        # æ‰“å°è¯¦ç»†è¯·æ±‚æ—¥å¿—
        self._log_request_details("Doubao (è±†åŒ…)", url, payload, functions)
        
        headers = {
            "Authorization": f"Bearer {self.model.api_key}",
            "Content-Type": "application/json"
        }
        
        try:
            response = requests.post(url, json=payload, headers=headers, timeout=60)
            
            # æ‰“å°å“åº”çŠ¶æ€
            logger.info(f"ğŸ“¡ å“åº”çŠ¶æ€ç : {response.status_code}")
            if response.status_code != 200:
                logger.error(f"âŒ API è°ƒç”¨å¤±è´¥:")
                logger.error(f"  Status Code: {response.status_code}")
                logger.error(f"  Response Headers: {dict(response.headers)}")
                logger.error(f"  Response: {response.text}")
            
            response.raise_for_status()
            
            result = response.json()
            choice = result["choices"][0]
            message = choice["message"]
            
            output = {}
            if message.get("content"):
                output["response"] = message["content"]
                logger.info(f"âœ… å“åº”å†…å®¹: {message['content'][:200]}...")
            
            # æ·»åŠ  token ä½¿ç”¨é‡ä¿¡æ¯
            if "usage" in result:
                output["usage"] = result["usage"]
                logger.info(f"ğŸ“Š Tokenä½¿ç”¨: {json.dumps(result['usage'], ensure_ascii=False)}")
            
            if message.get("tool_calls"):
                # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
                tool_call = message["tool_calls"][0]
                output["function_call"] = {
                    "name": tool_call["function"]["name"],
                    "arguments": json.loads(tool_call["function"]["arguments"])
                }
                logger.info(f"ğŸ”§ Tool Call: {tool_call['function']['name']}")
                logger.info(f"ğŸ“ Arguments: {json.dumps(output['function_call']['arguments'], ensure_ascii=False)}")
            
            return output
            
        except requests.exceptions.RequestException as e:
            logger.error(f"âŒ è¯·æ±‚å¼‚å¸¸:")
            logger.error(f"  Error: {str(e)}")
            if hasattr(e, 'response') and e.response is not None:
                logger.error(f"  Response Text: {e.response.text}")
            raise


def create_llm_service(model: LLMModel) -> LLMService:
    """åˆ›å»º LLM æœåŠ¡å®ä¾‹"""
    return LLMService(model)

