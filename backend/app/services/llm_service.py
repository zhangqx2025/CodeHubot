"""
å¤§æ¨¡å‹è°ƒç”¨æœåŠ¡
æ”¯æŒå¤šç§å›½äº§å’Œå›½é™…å¤§æ¨¡å‹
"""

import json
import requests
from typing import List, Dict, Any, Optional
from app.models.llm_model import LLMModel


class LLMService:
    """å¤§æ¨¡å‹è°ƒç”¨æœåŠ¡åŸºç±»"""
    
    def __init__(self, model: LLMModel):
        self.model = model
        self.api_base = model.api_base
        self.api_key = model.api_key
        self.model_name = model.name
        self.temperature = float(model.temperature) if model.temperature else 0.7
        self.max_tokens = model.max_tokens or 4096
        self.top_p = float(model.top_p) if model.top_p else 0.9
    
    def chat(
        self,
        messages: List[Dict[str, str]],
        functions: Optional[List[Dict[str, Any]]] = None,
        function_call: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        å‘é€èŠå¤©è¯·æ±‚åˆ°å¤§æ¨¡å‹
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨ [{"role": "user/assistant/system", "content": "..."}]
            functions: å¯ç”¨çš„å‡½æ•°åˆ—è¡¨ï¼ˆç”¨äº Function Callingï¼‰
            function_call: æ˜¯å¦å¼ºåˆ¶è°ƒç”¨å‡½æ•° ("auto", "none", {"name": "function_name"})
        
        Returns:
            {"response": "å›å¤å†…å®¹", "function_call": {...}}
        """
        provider = self.model.provider.lower()
        
        if provider == 'openai':
            return self._call_openai_api(messages, functions, function_call)
        elif provider == 'qwen':
            return self._call_qwen_api(messages, functions, function_call)
        elif provider == 'wenxin':
            return self._call_wenxin_api(messages, functions, function_call)
        elif provider == 'spark':
            return self._call_spark_api(messages, functions, function_call)
        elif provider == 'zhipu':
            return self._call_zhipu_api(messages, functions, function_call)
        elif provider == 'moonshot':
            return self._call_moonshot_api(messages, functions, function_call)
        elif provider == 'deepseek':
            return self._call_deepseek_api(messages, functions, function_call)
        elif provider == 'doubao':
            return self._call_doubao_api(messages, functions, function_call)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹æä¾›å•†: {provider}")
    
    def _call_openai_api(
        self,
        messages: List[Dict[str, str]],
        functions: Optional[List[Dict[str, Any]]] = None,
        function_call: Optional[str] = None
    ) -> Dict[str, Any]:
        """è°ƒç”¨ OpenAI API"""
        url = f"{self.api_base}/chat/completions"
        
        payload = {
            "model": self.model_name,
            "messages": messages,
            "temperature": float(self.temperature) if self.temperature else 0.7,
            "max_tokens": int(self.max_tokens) if self.max_tokens else 2000,
            "top_p": float(self.top_p) if self.top_p else 0.9
        }
        
        if functions:
            payload["functions"] = functions
            payload["function_call"] = function_call or "auto"
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        response = requests.post(url, json=payload, headers=headers, timeout=60)
        response.raise_for_status()
        
        result = response.json()
        choice = result["choices"][0]
        message = choice["message"]
        
        output = {}
        if message.get("content"):
            output["response"] = message["content"]
        if message.get("function_call"):
            output["function_call"] = {
                "name": message["function_call"]["name"],
                "arguments": json.loads(message["function_call"]["arguments"])
            }
        
        return output
    
    def _call_qwen_api(
        self,
        messages: List[Dict[str, str]],
        functions: Optional[List[Dict[str, Any]]] = None,
        function_call: Optional[str] = None
    ) -> Dict[str, Any]:
        """è°ƒç”¨é˜¿é‡Œé€šä¹‰åƒé—® APIï¼ˆå…¼å®¹ OpenAI æ ¼å¼ï¼‰"""
        # é€šä¹‰åƒé—®ä½¿ç”¨ DashScope SDKï¼Œè¿™é‡Œä½¿ç”¨ OpenAI å…¼å®¹æ¥å£
        # è‡ªåŠ¨ä¿®æ­£æ—§çš„ API Base URL
        api_base = self.api_base or 'https://dashscope.aliyuncs.com/compatible-mode/v1'
        if 'dashscope.aliyuncs.com/api/' in api_base:
            # è‡ªåŠ¨æ›¿æ¢ä¸ºå…¼å®¹æ¨¡å¼
            api_base = 'https://dashscope.aliyuncs.com/compatible-mode/v1'
        url = f"{api_base}/chat/completions"
        
        payload = {
            "model": self.model_name,
            "messages": messages,
            "temperature": float(self.temperature) if self.temperature else 0.7,
            "max_tokens": int(self.max_tokens) if self.max_tokens else 2000,
            "top_p": float(self.top_p) if self.top_p else 0.9
        }
        
        if functions:
            # é€šä¹‰åƒé—®æ”¯æŒ Function Calling
            payload["tools"] = [{"type": "function", "function": func} for func in functions]
            if function_call and function_call != "none":
                payload["tool_choice"] = "auto"
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        # æ‰“å°è¯·æ±‚ä¿¡æ¯ç”¨äºè°ƒè¯•
        print(f"ğŸ” è°ƒç”¨é€šä¹‰åƒé—® API:")
        print(f"  URL: {url}")
        print(f"  Model: {self.model_name}")
        print(f"  Has Functions: {bool(functions)}")
        if functions:
            print(f"  Functions Count: {len(functions)}")
            import json
            print(f"  Functions: {json.dumps(functions, ensure_ascii=False, indent=2)}")
        
        response = requests.post(url, json=payload, headers=headers, timeout=60)
        
        # å¦‚æœè¯·æ±‚å¤±è´¥ï¼Œæ‰“å°è¯¦ç»†é”™è¯¯
        if response.status_code != 200:
            print(f"âŒ API è°ƒç”¨å¤±è´¥:")
            print(f"  Status Code: {response.status_code}")
            print(f"  Response: {response.text}")
        
        response.raise_for_status()
        
        result = response.json()
        choice = result["choices"][0]
        message = choice["message"]
        
        output = {}
        if message.get("content"):
            output["response"] = message["content"]
        
        # æ·»åŠ  token ä½¿ç”¨é‡ä¿¡æ¯
        if "usage" in result:
            output["usage"] = result["usage"]
        
        if message.get("tool_calls"):
            # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            tool_call = message["tool_calls"][0]
            output["function_call"] = {
                "name": tool_call["function"]["name"],
                "arguments": json.loads(tool_call["function"]["arguments"])
            }
        
        return output
    
    def _call_wenxin_api(
        self,
        messages: List[Dict[str, str]],
        functions: Optional[List[Dict[str, Any]]] = None,
        function_call: Optional[str] = None
    ) -> Dict[str, Any]:
        """è°ƒç”¨ç™¾åº¦æ–‡å¿ƒä¸€è¨€ API"""
        # æ–‡å¿ƒä¸€è¨€éœ€è¦å…ˆè·å– access_token
        # ç®€åŒ–å®ç°ï¼šå‡è®¾ api_key æ˜¯ access_token
        url = f"{self.api_base or 'https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat'}/{self.model_name}"
        
        payload = {
            "messages": messages,
            "temperature": float(self.temperature) if self.temperature else 0.7,
            "top_p": float(self.top_p) if self.top_p else 0.9
        }
        
        if functions:
            payload["functions"] = functions
        
        params = {"access_token": self.api_key}
        
        response = requests.post(url, json=payload, params=params, timeout=60)
        response.raise_for_status()
        
        result = response.json()
        
        output = {"response": result.get("result", "")}
        
        if result.get("function_call"):
            output["function_call"] = {
                "name": result["function_call"]["name"],
                "arguments": json.loads(result["function_call"]["arguments"])
            }
        
        return output
    
    def _call_spark_api(
        self,
        messages: List[Dict[str, str]],
        functions: Optional[List[Dict[str, Any]]] = None,
        function_call: Optional[str] = None
    ) -> Dict[str, Any]:
        """è°ƒç”¨è®¯é£æ˜Ÿç« API"""
        # æ˜Ÿç«è®¤çŸ¥å¤§æ¨¡å‹éœ€è¦ WebSocket è¿æ¥ï¼Œè¿™é‡Œç®€åŒ–å®ç°
        # å®é™…ä½¿ç”¨åº”è¯¥ä½¿ç”¨å®˜æ–¹ SDK
        raise NotImplementedError("è®¯é£æ˜Ÿç« API éœ€è¦ä½¿ç”¨ WebSocketï¼Œè¯·ä½¿ç”¨å®˜æ–¹ SDK")
    
    def _call_zhipu_api(
        self,
        messages: List[Dict[str, str]],
        functions: Optional[List[Dict[str, Any]]] = None,
        function_call: Optional[str] = None
    ) -> Dict[str, Any]:
        """è°ƒç”¨æ™ºè°± GLM APIï¼ˆå…¼å®¹ OpenAI æ ¼å¼ï¼‰"""
        url = f"{self.api_base or 'https://open.bigmodel.cn/api/paas/v4'}/chat/completions"
        
        payload = {
            "model": self.model_name,
            "messages": messages,
            "temperature": float(self.temperature) if self.temperature else 0.7,
            "max_tokens": int(self.max_tokens) if self.max_tokens else 2000,
            "top_p": float(self.top_p) if self.top_p else 0.9
        }
        
        if functions:
            payload["tools"] = [{"type": "function", "function": func} for func in functions]
            if function_call and function_call != "none":
                payload["tool_choice"] = "auto"
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        response = requests.post(url, json=payload, headers=headers, timeout=60)
        response.raise_for_status()
        
        result = response.json()
        choice = result["choices"][0]
        message = choice["message"]
        
        output = {}
        if message.get("content"):
            output["response"] = message["content"]
        if message.get("tool_calls"):
            tool_call = message["tool_calls"][0]
            output["function_call"] = {
                "name": tool_call["function"]["name"],
                "arguments": json.loads(tool_call["function"]["arguments"])
            }
        
        return output
    
    def _call_moonshot_api(
        self,
        messages: List[Dict[str, str]],
        functions: Optional[List[Dict[str, Any]]] = None,
        function_call: Optional[str] = None
    ) -> Dict[str, Any]:
        """è°ƒç”¨æœˆä¹‹æš—é¢ Kimi APIï¼ˆå…¼å®¹ OpenAI æ ¼å¼ï¼‰"""
        return self._call_openai_api(messages, functions, function_call)
    
    def _call_deepseek_api(
        self,
        messages: List[Dict[str, str]],
        functions: Optional[List[Dict[str, Any]]] = None,
        function_call: Optional[str] = None
    ) -> Dict[str, Any]:
        """è°ƒç”¨ DeepSeek APIï¼ˆå…¼å®¹ OpenAI æ ¼å¼ï¼‰"""
        return self._call_openai_api(messages, functions, function_call)
    
    def _call_doubao_api(
        self,
        messages: List[Dict[str, str]],
        functions: Optional[List[Dict[str, Any]]] = None,
        function_call: Optional[str] = None
    ) -> Dict[str, Any]:
        """è°ƒç”¨ç«å±±å¼•æ“è±†åŒ… APIï¼ˆOpenAI å…¼å®¹æ¥å£ï¼‰"""
        # ç«å±±å¼•æ“æ–¹èˆŸå¹³å°ä½¿ç”¨ OpenAI å…¼å®¹çš„ API
        # API Base: https://ark.cn-beijing.volces.com/api/v3
        # å®Œæ•´è·¯å¾„: https://ark.cn-beijing.volces.com/api/v3/chat/completions
        
        api_base = self.model.api_base or 'https://ark.cn-beijing.volces.com/api/v3'
        
        # ç»Ÿä¸€å¤„ç† API Baseï¼Œç¡®ä¿æ²¡æœ‰å°¾éƒ¨æ–œæ 
        api_base = api_base.rstrip('/')
        
        # æ„å»ºå®Œæ•´ URL
        url = f"{api_base}/chat/completions"
        
        payload = {
            "model": self.model.name,
            "messages": messages,
            "temperature": float(self.model.temperature) if self.model.temperature else 0.7,
            "max_tokens": int(self.model.max_tokens) if self.model.max_tokens else 2000,
            "top_p": float(self.model.top_p) if self.model.top_p else 0.9
        }
        
        if functions:
            # è±†åŒ…æ”¯æŒ Function Callingï¼Œä½¿ç”¨ tools æ ¼å¼ï¼ˆOpenAI æ–°æ ¼å¼ï¼‰
            payload["tools"] = [{"type": "function", "function": func} for func in functions]
            if function_call and function_call != "none":
                payload["tool_choice"] = "auto"
        
        headers = {
            "Authorization": f"Bearer {self.model.api_key}",
            "Content-Type": "application/json"
        }
        
        # æ‰“å°è¯·æ±‚ä¿¡æ¯ç”¨äºè°ƒè¯•
        print(f"ğŸ” è°ƒç”¨ç«å±±å¼•æ“è±†åŒ… API:")
        print(f"  åŸå§‹ API Base: {self.model.api_base}")
        print(f"  å¤„ç†å API Base: {api_base}")
        print(f"  å®Œæ•´ URL: {url}")
        print(f"  Model Name: {self.model.name}")
        print(f"  API Key (å‰10ä½): {self.model.api_key[:10]}..." if self.model.api_key and len(self.model.api_key) > 10 else f"  API Key: {self.model.api_key}")
        print(f"  Messages Count: {len(messages)}")
        print(f"  Payload Model: {payload.get('model')}")
        if functions:
            print(f"  Functions Count: {len(functions)}")
        print(f"  å®Œæ•´ Payload: {json.dumps(payload, ensure_ascii=False, indent=2)}")
        
        try:
            response = requests.post(url, json=payload, headers=headers, timeout=60)
            
            # å¦‚æœè¯·æ±‚å¤±è´¥ï¼Œæ‰“å°è¯¦ç»†é”™è¯¯
            if response.status_code != 200:
                print(f"âŒ API è°ƒç”¨å¤±è´¥:")
                print(f"  Status Code: {response.status_code}")
                print(f"  Response Headers: {dict(response.headers)}")
                print(f"  Response: {response.text}")
            
            response.raise_for_status()
            
            result = response.json()
            choice = result["choices"][0]
            message = choice["message"]
            
            output = {}
            if message.get("content"):
                output["response"] = message["content"]
            
            # æ·»åŠ  token ä½¿ç”¨é‡ä¿¡æ¯
            if "usage" in result:
                output["usage"] = result["usage"]
            
            if message.get("tool_calls"):
                # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
                tool_call = message["tool_calls"][0]
                output["function_call"] = {
                    "name": tool_call["function"]["name"],
                    "arguments": json.loads(tool_call["function"]["arguments"])
                }
            
            return output
            
        except requests.exceptions.RequestException as e:
            print(f"âŒ è¯·æ±‚å¼‚å¸¸:")
            print(f"  Error: {str(e)}")
            if hasattr(e, 'response') and e.response is not None:
                print(f"  Response Text: {e.response.text}")
            raise


def create_llm_service(model: LLMModel) -> LLMService:
    """åˆ›å»º LLM æœåŠ¡å®ä¾‹"""
    return LLMService(model)

