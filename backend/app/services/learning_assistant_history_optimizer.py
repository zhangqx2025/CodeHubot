"""
å­¦ä¹ åŠ©æ‰‹å¯¹è¯å†å²ä¼˜åŒ–å™¨
ç­–ç•¥ï¼šåªä¿ç•™æœ€è¿‘Nä¸ªç”¨æˆ·é—®é¢˜ï¼Œä¸ä¿ç•™AIå›å¤

ä¼˜ç‚¹ï¼š
1. æå¤§èŠ‚çœTokenï¼ˆ85%+ï¼‰
2. çŸ¥è¯†åº“å†…å®¹æƒé‡å¤§å¹…æå‡ï¼ˆä»20%æå‡åˆ°64%ï¼‰
3. é¿å…å†å²AIå›å¤çš„é”™è¯¯å½±å“
4. ä¿ç•™é—®é¢˜è„‰ç»œï¼Œä¾¿äºç†è§£å­¦ç”Ÿå­¦ä¹ è½¨è¿¹
"""
from typing import List, Dict
import logging

logger = logging.getLogger(__name__)


class ConversationHistoryOptimizer:
    """å¯¹è¯å†å²ä¼˜åŒ–å™¨ - åªä¿ç•™ç”¨æˆ·é—®é¢˜ç‰ˆæœ¬"""
    
    def __init__(
        self,
        recent_user_questions: int = 5  # ä¿ç•™æœ€è¿‘Nä¸ªç”¨æˆ·é—®é¢˜
    ):
        """
        åˆå§‹åŒ–ä¼˜åŒ–å™¨
        
        Args:
            recent_user_questions: ä¿ç•™æœ€è¿‘Nä¸ªç”¨æˆ·é—®é¢˜ï¼ˆä¸åŒ…å«AIå›å¤ï¼‰
                - æ¨èå€¼ï¼š5ä¸ªï¼ˆå¹³è¡¡è®°å¿†å’Œæˆæœ¬ï¼‰
                - ä¿å®ˆå€¼ï¼š3ä¸ªï¼ˆæœ€çœTokenï¼‰
                - æ¿€è¿›å€¼ï¼š8ä¸ªï¼ˆæ›´é•¿çš„é—®é¢˜è„‰ç»œï¼‰
        """
        self.recent_user_questions = recent_user_questions
        logger.info(f"ğŸ’¡ å¯¹è¯å†å²ä¼˜åŒ–å™¨å·²åˆå§‹åŒ–: ä¿ç•™æœ€è¿‘{recent_user_questions}ä¸ªç”¨æˆ·é—®é¢˜")
    
    def optimize_history(self, messages) -> List[Dict[str, str]]:
        """
        ä¼˜åŒ–å¯¹è¯å†å² - åªä¿ç•™ç”¨æˆ·é—®é¢˜
        
        ç­–ç•¥ï¼š
        - åªä¿ç•™æœ€è¿‘Nä¸ªç”¨æˆ·é—®é¢˜
        - å®Œå…¨ä¸¢å¼ƒæ‰€æœ‰AIå†å²å›å¤
        
        ä¸ºä»€ä¹ˆåªä¿ç•™ç”¨æˆ·é—®é¢˜ï¼Ÿ
        1. æå¤§èŠ‚çœTokenï¼šAIå›å¤é€šå¸¸300-500å­—ï¼Œç”¨æˆ·é—®é¢˜åªæœ‰50-100å­—
        2. çŸ¥è¯†åº“ç»å¯¹ä¼˜å…ˆï¼šæ¯æ¬¡éƒ½é‡æ–°ä»çŸ¥è¯†åº“æ£€ç´¢ï¼Œä¿è¯ç­”æ¡ˆæœ€æ–°æœ€å‡†ç¡®
        3. é¿å…é”™è¯¯ä¼ æ’­ï¼šå†å²AIå›å¤å¯èƒ½æœ‰è¯¯ï¼Œä¸åº”è¯¥å½±å“æ–°å›ç­”
        4. ä¿ç•™é—®é¢˜è„‰ç»œï¼šå¯ä»¥çœ‹åˆ°å­¦ç”Ÿçš„å­¦ä¹ è½¨è¿¹å’Œæ€è€ƒè¿‡ç¨‹
        
        Args:
            messages: åŸå§‹æ¶ˆæ¯åˆ—è¡¨ï¼ˆORMå¯¹è±¡æˆ–å­—å…¸ï¼ŒæŒ‰æ—¶é—´å‡åºï¼‰
        
        Returns:
            ä¼˜åŒ–åçš„æ¶ˆæ¯åˆ—è¡¨ï¼Œæ ¼å¼ï¼š[{"role": "user", "content": "..."}]
        
        Example:
            åŸå§‹ï¼š[Q1, A1, Q2, A2, Q3, A3, Q4, A4, Q5, A5]ï¼ˆ10æ¡ï¼‰
            ä¼˜åŒ–ï¼š[Q1, Q2, Q3, Q4, Q5]ï¼ˆ5æ¡ï¼Œå¦‚æœrecent_user_questions=5ï¼‰
            TokenèŠ‚çœï¼šçº¦85%
        """
        if not messages:
            return []
        
        # æå–æ‰€æœ‰ç”¨æˆ·æ¶ˆæ¯
        user_messages = []
        for msg in messages:
            # å…¼å®¹ORMå¯¹è±¡å’Œå­—å…¸
            role = msg.role if hasattr(msg, 'role') else msg.get('role')
            if role == 'user':
                user_messages.append(msg)
        
        # åªä¿ç•™æœ€è¿‘Nä¸ªç”¨æˆ·é—®é¢˜
        if len(user_messages) > self.recent_user_questions:
            user_messages = user_messages[-self.recent_user_questions:]
        
        # è½¬æ¢ä¸ºChatæ ¼å¼
        result = self._convert_to_chat_format(user_messages)
        
        # è®°å½•ä¼˜åŒ–æ•ˆæœ
        original_count = len(messages)
        optimized_count = len(result)
        if original_count > 0:
            save_percentage = round((1 - optimized_count / original_count) * 100, 1)
            logger.info(
                f"ğŸ’° å¯¹è¯å†å²ä¼˜åŒ–: {original_count}æ¡ â†’ {optimized_count}æ¡ "
                f"(èŠ‚çœ{save_percentage}%)"
            )
        
        return result
    
    def _convert_to_chat_format(self, messages) -> List[Dict[str, str]]:
        """
        å°†æ•°æ®åº“æ¶ˆæ¯è½¬æ¢ä¸ºLLM Chatæ ¼å¼
        
        Args:
            messages: æ•°æ®åº“æ¶ˆæ¯å¯¹è±¡åˆ—è¡¨ï¼ˆORMå¯¹è±¡æˆ–å­—å…¸ï¼‰
        
        Returns:
            Chatæ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨
        """
        result = []
        for msg in messages:
            # å…¼å®¹ORMå¯¹è±¡å’Œå­—å…¸
            role = msg.role if hasattr(msg, 'role') else msg.get('role')
            content = msg.content if hasattr(msg, 'content') else msg.get('content')
            
            if role in ['user', 'assistant']:
                result.append({
                    "role": role,
                    "content": content
                })
        
        return result
    
    def get_token_estimate(self, messages) -> Dict[str, int]:
        """
        ä¼°ç®—Tokenæ¶ˆè€—ï¼ˆä¼˜åŒ–å‰ vs ä¼˜åŒ–åï¼‰
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨ï¼ˆORMå¯¹è±¡æˆ–å­—å…¸ï¼‰
        
        Returns:
            Tokenä¼°ç®—ä¿¡æ¯
        """
        if not messages:
            return {
                'original_count': 0,
                'original_tokens': 0,
                'optimized_count': 0,
                'optimized_tokens': 0,
                'saved_tokens': 0,
                'save_percentage': 0
            }
        
        # ç®€å•ä¼°ç®—ï¼š1ä¸ªæ±‰å­—â‰ˆ2 tokensï¼Œ1ä¸ªè‹±æ–‡å•è¯â‰ˆ1.3 tokens
        # è¿™é‡Œç”¨å­—ç¬¦æ•° * 1.5 ä½œä¸ºç²—ç•¥ä¼°ç®—
        
        original_tokens = 0
        for msg in messages:
            content = msg.content if hasattr(msg, 'content') else msg.get('content', '')
            original_tokens += len(content) * 1.5
        
        optimized_messages = self.optimize_history(messages)
        optimized_tokens = sum(
            len(msg['content']) * 1.5 
            for msg in optimized_messages
        )
        
        saved_tokens = original_tokens - optimized_tokens
        save_percentage = round((saved_tokens / original_tokens) * 100, 1) if original_tokens > 0 else 0
        
        return {
            'original_count': len(messages),
            'original_tokens': int(original_tokens),
            'optimized_count': len(optimized_messages),
            'optimized_tokens': int(optimized_tokens),
            'saved_tokens': int(saved_tokens),
            'save_percentage': save_percentage
        }


# ============================================================================
# ä½¿ç”¨ç¤ºä¾‹
# ============================================================================

"""
ä½¿ç”¨ç¤ºä¾‹ï¼š

from app.services.learning_assistant_history_optimizer import ConversationHistoryOptimizer

# 1. åˆ›å»ºä¼˜åŒ–å™¨
optimizer = ConversationHistoryOptimizer(
    recent_user_questions=5  # ä¿ç•™æœ€è¿‘5ä¸ªç”¨æˆ·é—®é¢˜
)

# 2. ä¼˜åŒ–å¯¹è¯å†å²
messages = db.query(LearningAssistantMessage).filter(...).all()
optimized = optimizer.optimize_history(messages)

# 3. æŸ¥çœ‹ä¼˜åŒ–æ•ˆæœ
stats = optimizer.get_token_estimate(messages)
print(f"èŠ‚çœToken: {stats['save_percentage']}%")

ç¤ºä¾‹æ•ˆæœï¼š
- åŸå§‹ï¼š10è½®å¯¹è¯ = 20æ¡æ¶ˆæ¯ï¼ˆ10ä¸ªé—®é¢˜ + 10ä¸ªAIå›å¤ï¼‰
- ä¼˜åŒ–åï¼šåªä¿ç•™æœ€è¿‘5ä¸ªç”¨æˆ·é—®é¢˜
- TokenèŠ‚çœï¼šçº¦85%
- çŸ¥è¯†åº“æƒé‡ï¼šä»20%æå‡åˆ°64%
"""

