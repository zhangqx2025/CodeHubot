"""
AIå­¦ä¹ åŠ©æ‰‹æ ¸å¿ƒæœåŠ¡
"""
from typing import Dict, List, Optional
from sqlalchemy.orm import Session
from datetime import datetime, timedelta
import uuid as uuid_lib
import hashlib
import logging

from app.models.learning_assistant import (
    LearningAssistantConversation,
    LearningAssistantMessage,
    StudentLearningProfile,
    ContentModerationLog
)
from app.models.pbl import PBLCourse, PBLUnit
from app.services.content_moderation_service import ContentModerationService
from app.services.learning_assistant_history_optimizer import ConversationHistoryOptimizer

logger = logging.getLogger(__name__)


class LearningAssistantService:
    """å­¦ä¹ åŠ©æ‰‹æ ¸å¿ƒæœåŠ¡"""
    
    def __init__(self, db: Session):
        self.db = db
        self.moderator = ContentModerationService(db)
        # åˆå§‹åŒ–å¯¹è¯å†å²ä¼˜åŒ–å™¨ï¼šåªä¿ç•™æœ€è¿‘5ä¸ªç”¨æˆ·é—®é¢˜
        self.history_optimizer = ConversationHistoryOptimizer(
            recent_user_questions=5  # å¯æ ¹æ®å®é™…æ•ˆæœè°ƒæ•´ä¸º3-8
        )
    
    async def chat(
        self,
        user_id: int,
        message: str,
        context: Dict,
        conversation_id: Optional[str] = None
    ) -> Dict:
        """
        æ ¸å¿ƒå¯¹è¯æ–¹æ³•
        
        Args:
            user_id: ç”¨æˆ·ID
            message: ç”¨æˆ·æ¶ˆæ¯
            context: å­¦ä¹ ä¸Šä¸‹æ–‡
            conversation_id: ä¼šè¯UUIDï¼ˆå¯é€‰ï¼‰
        
        Returns:
            AIå›å¤åŠç›¸å…³ä¿¡æ¯
        """
        
        # 1. å†…å®¹å®‰å…¨å®¡æ ¸ï¼ˆç”¨æˆ·è¾“å…¥ï¼‰
        moderation_result = await self.moderator.check(
            content=message,
            content_type='user_message'
        )
        
        if moderation_result['status'] == 'blocked':
            # âœ… å³ä¾¿æ‹¦æˆªäº†ï¼Œä¹Ÿè¦ä¿å­˜è¿™æ¡è¿è§„æ¶ˆæ¯ï¼Œä»¥ä¾¿ç®¡ç†å‘˜åç»­å®¡è®¡
            try:
                # 3.1 è·å–æˆ–åˆ›å»ºä¼šè¯
                conversation = await self._get_or_create_conversation(
                    user_id=user_id,
                    conversation_id=conversation_id,
                    context=context
                )
                # 3.2 ä¿å­˜è¿è§„æ¶ˆæ¯
                user_message = await self._save_message(
                    conversation_id=conversation.id,
                    role='user',
                    content=message,
                    context_snapshot=context,
                    moderation_result=moderation_result
                )
                # 3.3 è®°å½•å®¡è®¡æ—¥å¿—
                await self._log_moderation(
                    user_id=user_id,
                    conversation_id=conversation.id,
                    message_id=user_message.id,
                    content_type='user_message',
                    content=message,
                    result=moderation_result
                )
            except Exception as e:
                logger.error(f"ä¿å­˜è¿è§„æ¶ˆæ¯å¤±è´¥: {str(e)}")

            return {
                'response': 'æŠ±æ­‰ï¼Œä½ çš„æ¶ˆæ¯åŒ…å«ä¸é€‚å½“çš„å†…å®¹ï¼Œå·²è¢«ç³»ç»Ÿæ‹¦æˆªã€‚è¯·éµå®ˆå­¦ä¹ è§„èŒƒã€‚',
                'blocked': True,
                'reason': moderation_result.get('reason'),
                'conversation_id': conversation_id # å°½å¯èƒ½è¿”å›ID
            }
        
        # 2. è·å–æˆ–åˆ›å»ºä¼šè¯
        conversation = await self._get_or_create_conversation(
            user_id=user_id,
            conversation_id=conversation_id,
            context=context
        )
        
        # 3. ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
        user_message = await self._save_message(
            conversation_id=conversation.id,
            role='user',
            content=message,
            context_snapshot=context,
            moderation_result=moderation_result
        )
        
        # 4. è®°å½•å®¡æ ¸æ—¥å¿—ï¼ˆå¦‚æœæœ‰è­¦å‘Šæˆ–æ‹¦æˆªï¼‰
        if moderation_result['status'] in ['warning', 'blocked']:
            await self._log_moderation(
                user_id=user_id,
                conversation_id=conversation.id,
                message_id=user_message.id,
                content_type='user_message',
                content=message,
                result=moderation_result
            )
        
        # 5. æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡
        full_context = await self._build_full_context(
            user_id=user_id,
            conversation=conversation,
            current_context=context
        )
        
        # 6. è°ƒç”¨LLMç”Ÿæˆå›å¤
        start_time = datetime.now()
        llm_response = await self._call_llm(
            message=message,
            context=full_context,
            conversation_history=await self._get_recent_messages(conversation.id, limit=10)
        )
        response_time = int((datetime.now() - start_time).total_seconds() * 1000)
        
        # 7. å†…å®¹å®‰å…¨å®¡æ ¸ï¼ˆAIå›å¤ï¼‰
        # âš ï¸ ä¸´æ—¶ç¦ç”¨AIå›å¤å®¡æ ¸ï¼Œé¿å…è¯¯åˆ¤æŠ€æœ¯å†…å®¹
        # TODO: ä¼˜åŒ–æ•æ„Ÿè¯è¡¨åé‡æ–°å¯ç”¨
        ai_moderation = await self.moderator.check(
            content=llm_response['content'],
            content_type='ai_response'
        )
        
        # æš‚æ—¶æ³¨é‡Šæ‰æ‹¦æˆªé€»è¾‘
        # if ai_moderation['status'] == 'blocked':
        #     llm_response['content'] = 'æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚å»ºè®®ä½ å‘è€å¸ˆè¯·æ•™ã€‚'
        
        # 8. ä¿å­˜AIå›å¤
        ai_message = await self._save_message(
            conversation_id=conversation.id,
            role='assistant',
            content=llm_response['content'],
            knowledge_sources=llm_response.get('knowledge_sources'),
            token_usage=llm_response.get('token_usage'),
            model_used=llm_response.get('model'),
            response_time_ms=response_time,
            moderation_result=ai_moderation
        )
        
        # 9. æ›´æ–°ä¼šè¯ç»Ÿè®¡
        await self._update_conversation_stats(conversation.id)
        
        # 10. åˆ·æ–°conversationå¯¹è±¡ä»¥è·å–æœ€æ–°çš„message_count
        self.db.refresh(conversation)
        
        # 11. å¦‚æœæ˜¯é¦–æ¬¡å¯¹è¯ï¼Œç”Ÿæˆæ™ºèƒ½æ ‡é¢˜
        suggested_title = None
        if conversation.message_count == 2:  # 2æ¡æ¶ˆæ¯ = ç”¨æˆ·é¦–æ¬¡æé—® + AIé¦–æ¬¡å›å¤
            try:
                suggested_title = await self._generate_conversation_title(
                    user_message=message,
                    ai_response=llm_response['content']
                )
                if suggested_title:
                    conversation.title = suggested_title
                    self.db.commit()
                    logger.info(f"âœ… è‡ªåŠ¨ç”Ÿæˆä¼šè¯æ ‡é¢˜: {suggested_title}")
                else:
                    logger.warning(f"âš ï¸ æ ‡é¢˜ç”Ÿæˆè¿”å›ä¸ºç©º")
            except Exception as e:
                logger.error(f"âŒ ç”Ÿæˆä¼šè¯æ ‡é¢˜å¤±è´¥: {str(e)}", exc_info=True)
        
        # 11. å¼‚æ­¥æ›´æ–°å­¦ç”Ÿæ¡£æ¡ˆ
        try:
            await self._update_student_profile(user_id, message, context)
        except Exception as e:
            logger.error(f"æ›´æ–°å­¦ç”Ÿæ¡£æ¡ˆå¤±è´¥: {str(e)}")
        
        return {
            'response': llm_response['content'],
            'conversation_id': conversation.uuid,
            'message_id': ai_message.uuid,
            'suggested_title': suggested_title,  # è¿”å›å»ºè®®çš„æ ‡é¢˜
            'knowledge_sources': llm_response.get('knowledge_sources'),
            'token_usage': llm_response.get('token_usage'),
            'blocked': False
        }
    
    async def _get_or_create_conversation(
        self,
        user_id: int,
        conversation_id: Optional[str],
        context: Dict
    ) -> LearningAssistantConversation:
        """è·å–æˆ–åˆ›å»ºä¼šè¯"""
        
        if conversation_id:
            # æŸ¥æ‰¾å·²å­˜åœ¨çš„æ´»è·ƒä¼šè¯
            conversation = self.db.query(LearningAssistantConversation).filter(
                LearningAssistantConversation.uuid == conversation_id,
                LearningAssistantConversation.user_id == user_id,
                LearningAssistantConversation.is_active == 1
            ).first()
            
            if conversation:
                return conversation
        
        # åˆ›å»ºæ–°ä¼šè¯
        course_uuid = context.get('course_uuid')
        course_name = context.get('course_name')
        unit_uuid = context.get('unit_uuid')
        unit_name = context.get('unit_name')
        
        # å°è¯•ä»æ•°æ®åº“è·å–è¯¾ç¨‹å’Œå•å…ƒåç§°ï¼ˆå¦‚æœå‰ç«¯æ²¡ä¼ ï¼‰
        if course_uuid and not course_name:
            course = self.db.query(PBLCourse).filter(PBLCourse.uuid == course_uuid).first()
            if course:
                course_name = course.title
                
        if unit_uuid and not unit_name:
            unit = self.db.query(PBLUnit).filter(PBLUnit.uuid == unit_uuid).first()
            if unit:
                unit_name = unit.title

        conversation = LearningAssistantConversation(
            uuid=str(uuid_lib.uuid4()),
            user_id=user_id,
            title='æ–°çš„å¯¹è¯',
            course_uuid=course_uuid,
            course_name=course_name,
            unit_uuid=unit_uuid,
            unit_name=unit_name,
            source='course_learning' if course_uuid else 'manual'
        )
        
        # å¤„ç†å½“å‰èµ„æºä¿¡æ¯
        if context.get('current_resource'):
            resource = context['current_resource']
            conversation.current_resource_id = resource.get('uuid')
            conversation.current_resource_type = resource.get('type')
            conversation.current_resource_title = resource.get('title')
        
        self.db.add(conversation)
        self.db.commit()
        self.db.refresh(conversation)
        
        return conversation

    def clear_all_conversations(self, user_id: int) -> int:
        """æ¸…ç©ºæ‰€æœ‰ä¼šè¯ï¼ˆè½¯åˆ é™¤ï¼‰"""
        # æ›´æ–°è¯¥ç”¨æˆ·çš„æ‰€æœ‰æ´»è·ƒä¼šè¯ä¸ºéæ´»è·ƒ
        result = self.db.query(LearningAssistantConversation).filter(
            LearningAssistantConversation.user_id == user_id,
            LearningAssistantConversation.is_active == 1
        ).update({LearningAssistantConversation.is_active: 0}, synchronize_session=False)
        
        self.db.commit()
        return result
    
    async def _save_message(
        self,
        conversation_id: int,
        role: str,
        content: str,
        context_snapshot: Dict = None,
        knowledge_sources: List = None,
        token_usage: Dict = None,
        model_used: str = None,
        response_time_ms: int = None,
        moderation_result: Dict = None
    ) -> LearningAssistantMessage:
        """ä¿å­˜æ¶ˆæ¯"""
        
        # è®¡ç®—å†…å®¹å“ˆå¸Œ
        content_hash = hashlib.md5(content.encode('utf-8')).hexdigest()
        
        # æå–å®¡æ ¸ç»“æœ
        was_blocked = 0
        if moderation_result and moderation_result.get('status') == 'blocked':
            was_blocked = 1
            
        message = LearningAssistantMessage(
            uuid=str(uuid_lib.uuid4()),
            conversation_id=conversation_id,
            role=role,
            content=content,
            content_hash=content_hash,
            context_snapshot=context_snapshot,
            knowledge_sources=knowledge_sources,
            token_usage=token_usage,
            model_used=model_used,
            response_time_ms=response_time_ms,
            moderation_result=moderation_result,
            was_blocked=was_blocked  # âœ… æ˜¾å¼è®¾ç½®æ‹¦æˆªçŠ¶æ€
        )
        
        self.db.add(message)
        self.db.commit()
        self.db.refresh(message)
        
        return message
    
    async def _build_full_context(
        self,
        user_id: int,
        conversation: LearningAssistantConversation,
        current_context: Dict
    ) -> str:
        """æ„å»ºå®Œæ•´çš„ä¸ªæ€§åŒ–ä¸Šä¸‹æ–‡ï¼ˆä¸¥æ ¼çº¦æŸç‰ˆï¼‰"""
        
        # 1. ä¼˜å…ˆè·å–æ•°æ®åº“ä¸­å®šä¹‰çš„ä¸¥æ ¼ç³»ç»Ÿæç¤ºè¯
        from app.models.agent import Agent
        system_agent = self.db.query(Agent).filter(
            Agent.uuid == 'system-learning-assistant'
        ).first()
        
        # å¦‚æœæ•°æ®åº“æœ‰å€¼ï¼Œç›´æ¥ç”¨æ•°æ®åº“çš„ï¼›å¦åˆ™ç”¨ä»£ç é‡Œçš„å¼ºåŠ›å…œåº•
        base_prompt = system_agent.system_prompt if (system_agent and system_agent.system_prompt) else self._get_base_system_prompt()
        
        # 2. è·å–å­¦ç”Ÿæ¡£æ¡ˆ
        profile = await self._get_student_profile(user_id)
        
        # 3. æ„å»ºä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        context_parts = [
            base_prompt,
            "\n[å­¦ç”Ÿå­¦ä¹ çŠ¶æ€]"
        ]
        
        if profile:
            context_parts.append(f"æ€»æé—®æ•°: {profile.total_questions}")
            if profile.weak_points:
                context_parts.append(f"è–„å¼±çŸ¥è¯†ç‚¹: {', '.join(profile.weak_points[:5])}")
        
        context_parts.append("\n[å½“å‰å­¦ä¹ åœºæ™¯]")
        context_parts.append(self._format_current_context(current_context))
        
        return "\n".join(context_parts)
    
    def _get_base_system_prompt(self) -> str:
        """è·å–å¼ºåŠ›å…œåº•æç¤ºè¯"""
        return """ä½ æ˜¯ä¸€ä¸ªä¸“é—¨ä¸ºã€äººå·¥æ™ºèƒ½è¯¾ç¨‹ã€‘è®¾è®¡çš„ä¸“ä¸šAIå­¦ä¹ åŠ©æ‰‹ã€‚
ã€æ ¸å¿ƒç¦ä»¤ã€‘
1. ç¦æ­¢è¿›è¡Œä»»ä½•å½¢å¼çš„æƒ…æ„Ÿå…±æƒ…ã€å¿ƒç†å®‰æ…°æˆ–ç”Ÿæ´»é—²èŠã€‚
2. å¯¹äºä»»ä½•éAIå­¦ä¹ çš„è¯é¢˜ï¼Œå¿…é¡»ç¤¼è²Œä½†å†·æ¼ åœ°æ‹’ç»ï¼Œå¹¶è¦æ±‚å­¦ç”Ÿæé—®AIçŸ¥è¯†ç‚¹ã€‚
3. åªèƒ½å›ç­”ï¼šäººå·¥æ™ºèƒ½ã€æœºå™¨å­¦ä¹ ã€Pythonç¼–ç¨‹ï¼ˆAIæ–¹å‘ï¼‰ã€æœºå™¨äººåŠæœ¬è¯¾ç¨‹çŸ¥è¯†å†…å®¹ã€‚
4. å›å¤é£æ ¼ï¼šä¸“ä¸šã€å­¦æœ¯ã€ç®€æ´ã€‚ç¦æ­¢å›å¤â€œæˆ‘ç†è§£ä½ â€ã€â€œä¸è¦æ°”é¦â€ç­‰åºŸè¯ã€‚"""
    
    def _format_current_context(self, context: Dict) -> str:
        """æ ¼å¼åŒ–å½“å‰å­¦ä¹ ä¸Šä¸‹æ–‡"""
        parts = []
        
        if context.get('course_name'):
            parts.append(f"è¯¾ç¨‹ï¼š{context['course_name']}")
        
        if context.get('unit_name'):
            parts.append(f"å•å…ƒï¼š{context['unit_name']}")
        
        if context.get('current_resource'):
            resource = context['current_resource']
            parts.append(
                f"å½“å‰æ­£åœ¨å­¦ä¹ ï¼š{resource.get('type')} - {resource.get('title')}"
            )
        
        return "\n".join(parts) if parts else "é€šç”¨å­¦ä¹ åœºæ™¯"
    
    async def _retrieve_knowledge(
        self,
        query: str,
        top_k: int = 5,
        similarity_threshold: float = 0.70
    ) -> List[Dict]:
        """
        ä»å®˜æ–¹çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³çŸ¥è¯†ï¼ˆRAGæ ¸å¿ƒï¼‰
        
        Args:
            query: ç”¨æˆ·é—®é¢˜
            top_k: è¿”å›æœ€ç›¸å…³çš„Nä¸ªæ–‡æœ¬å—
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
            
        Returns:
            List[Dict]: æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        from app.models.agent import Agent
        from app.models.knowledge_base import AgentKnowledgeBase, KnowledgeBase
        from app.models.document import DocumentChunk
        from app.services.embedding_service import get_embedding_service
        import numpy as np
        
        try:
            # 1. è·å–å­¦ä¹ åŠ©æ‰‹å…³è”çš„çŸ¥è¯†åº“
            system_agent = self.db.query(Agent).filter(
                Agent.uuid == 'system-learning-assistant'
            ).first()
            
            if not system_agent:
                logger.warning("æœªæ‰¾åˆ°ç³»ç»Ÿå­¦ä¹ åŠ©æ‰‹æ™ºèƒ½ä½“")
                return []
            
            kb_associations = self.db.query(AgentKnowledgeBase).filter(
                AgentKnowledgeBase.agent_id == system_agent.id,
                AgentKnowledgeBase.is_enabled == 1
            ).order_by(AgentKnowledgeBase.priority.desc()).all()
            
            if not kb_associations:
                logger.info("å­¦ä¹ åŠ©æ‰‹æœªå…³è”ä»»ä½•çŸ¥è¯†åº“")
                return []
            
            logger.info(f"å­¦ä¹ åŠ©æ‰‹å…³è”äº† {len(kb_associations)} ä¸ªçŸ¥è¯†åº“")
            
            # 2. å‘é‡åŒ–ç”¨æˆ·é—®é¢˜
            embedding_service = get_embedding_service()
            query_vector = await embedding_service.embed_text(query)
            
            if not query_vector:
                logger.warning("é—®é¢˜å‘é‡åŒ–å¤±è´¥")
                return []
            
            logger.info("é—®é¢˜å‘é‡åŒ–æˆåŠŸ")
            
            # 3. åœ¨æ‰€æœ‰å…³è”çš„çŸ¥è¯†åº“ä¸­æ£€ç´¢
            all_results = []
            
            for assoc in kb_associations:
                kb = self.db.query(KnowledgeBase).filter(
                    KnowledgeBase.id == assoc.knowledge_base_id
                ).first()
                
                if not kb:
                    continue
                
                logger.info(f"æ£€ç´¢çŸ¥è¯†åº“: {kb.name}")
                
                # è·å–è¯¥çŸ¥è¯†åº“çš„æ‰€æœ‰å·²å‘é‡åŒ–æ–‡æœ¬å—
                chunks = self.db.query(DocumentChunk).filter(
                    DocumentChunk.knowledge_base_id == kb.id,
                    DocumentChunk.embedding_vector.isnot(None)
                ).all()
                
                if not chunks:
                    logger.info(f"çŸ¥è¯†åº“ '{kb.name}' ä¸­æ²¡æœ‰å·²å‘é‡åŒ–çš„å†…å®¹")
                    continue
                
                logger.info(f"çŸ¥è¯†åº“ '{kb.name}' ä¸­æ‰¾åˆ° {len(chunks)} ä¸ªæ–‡æœ¬å—")
                
                # 4. è®¡ç®—ç›¸ä¼¼åº¦
                threshold = float(assoc.similarity_threshold) if assoc.similarity_threshold else similarity_threshold
                
                for chunk in chunks:
                    try:
                        chunk_vector = chunk.embedding_vector
                        
                        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
                        similarity = embedding_service.calculate_similarity(query_vector, chunk_vector)
                        
                        if similarity >= threshold:
                            all_results.append({
                                'chunk_id': chunk.id,
                                'content': chunk.content,
                                'similarity': similarity,
                                'kb_name': kb.name,
                                'kb_id': kb.id,
                                'document_id': chunk.document_id
                            })
                    
                    except Exception as e:
                        logger.error(f"è®¡ç®—ç›¸ä¼¼åº¦å¤±è´¥: {str(e)}")
                        continue
            
            # 5. æŒ‰ç›¸ä¼¼åº¦æ’åºï¼Œå– Top-K
            all_results.sort(key=lambda x: x['similarity'], reverse=True)
            final_results = all_results[:top_k]
            
            logger.info(f"æ£€ç´¢å®Œæˆï¼Œå…±æ‰¾åˆ° {len(all_results)} ä¸ªç›¸å…³æ–‡æœ¬å—ï¼Œè¿”å› Top-{len(final_results)}")
            
            return final_results
        
        except Exception as e:
            logger.error(f"çŸ¥è¯†åº“æ£€ç´¢å¤±è´¥: {str(e)}", exc_info=True)
            return []
    
    async def _call_llm(
        self,
        message: str,
        context: str,
        conversation_history: List[LearningAssistantMessage]
    ) -> Dict:
        """
        è°ƒç”¨LLMç”Ÿæˆå›å¤ï¼ˆé›†æˆRAGæ£€ç´¢ï¼‰
        """
        from app.models.llm_model import LLMModel
        from app.services.llm_service import create_llm_service
        
        # 1. è·å–ç³»ç»Ÿå­¦ä¹ åŠ©æ‰‹çš„LLMæ¨¡å‹é…ç½®
        from app.models.agent import Agent
        
        system_agent = self.db.query(Agent).filter(
            Agent.uuid == 'system-learning-assistant'
        ).first()
        
        # 2. è·å–LLMæ¨¡å‹ï¼ˆä¼˜å…ˆä½¿ç”¨æ™ºèƒ½ä½“é…ç½®çš„ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤æ¨¡å‹ï¼‰
        llm_model = None
        if system_agent and system_agent.llm_model_id:
            llm_model = self.db.query(LLMModel).filter(
                LLMModel.id == system_agent.llm_model_id,
                LLMModel.is_active == 1
            ).first()
        
        # å¦‚æœæ²¡æœ‰é…ç½®ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹
        if not llm_model:
            llm_model = self.db.query(LLMModel).filter(
                LLMModel.is_default == 1,
                LLMModel.is_active == 1
            ).first()
        
        if not llm_model:
            logger.error("æœªæ‰¾åˆ°å¯ç”¨çš„LLMæ¨¡å‹")
            return {
                'content': 'æŠ±æ­‰ï¼Œç³»ç»Ÿæš‚æ—¶æ— æ³•å›ç­”ã€‚è¯·ç¨åå†è¯•æˆ–è”ç³»è€å¸ˆã€‚',
                'knowledge_sources': [],
                'token_usage': {'prompt': 0, 'completion': 0, 'total': 0},
                'model': 'unknown'
            }
        
        # 3. ã€RAGæ£€ç´¢ã€‘ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³å†…å®¹
        knowledge_results = await self._retrieve_knowledge(message, top_k=3)
        
        # 4. æ„å»ºå¢å¼ºåçš„ä¸Šä¸‹æ–‡
        enhanced_context = context
        
        if knowledge_results:
            logger.info(f"æ£€ç´¢åˆ° {len(knowledge_results)} æ¡ç›¸å…³çŸ¥è¯†")
            
            # å°†æ£€ç´¢ç»“æœæ’å…¥åˆ°ç³»ç»Ÿæç¤ºè¯ä¸­
            knowledge_text = "\n\n[å‚è€ƒèµ„æ–™]\n"
            knowledge_text += "ä»¥ä¸‹å†…å®¹æ¥è‡ªè¯¾ç¨‹å®˜æ–¹æ–‡æ¡£ï¼Œè¯·ä¼˜å…ˆå‚è€ƒè¿™äº›å†…å®¹å›ç­”ï¼š\n\n"
            
            for i, result in enumerate(knowledge_results, 1):
                knowledge_text += f"ã€èµ„æ–™{i}ã€‘ï¼ˆç›¸ä¼¼åº¦ï¼š{result['similarity']:.2%}ï¼‰\n"
                knowledge_text += f"{result['content']}\n\n"
            
            knowledge_text += "---\nè¯·åŸºäºä»¥ä¸Šå‚è€ƒèµ„æ–™ï¼Œç»“åˆä½ çš„çŸ¥è¯†ï¼Œä¸ºå­¦ç”Ÿæä¾›å‡†ç¡®çš„å›ç­”ã€‚"
            
            enhanced_context = f"{context}\n{knowledge_text}"
        else:
            logger.info("æœªæ£€ç´¢åˆ°ç›¸å…³çŸ¥è¯†ï¼Œä½¿ç”¨é€šç”¨çŸ¥è¯†å›ç­”")
        
        # 5. æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = [
            {"role": "system", "content": enhanced_context}
        ]
        
        # ã€ä¼˜åŒ–ã€‘ä½¿ç”¨æ™ºèƒ½å†å²ä¼˜åŒ–å™¨ï¼šåªä¿ç•™æœ€è¿‘5ä¸ªç”¨æˆ·é—®é¢˜
        # ä¼˜ç‚¹ï¼šèŠ‚çœ85% Tokenï¼ŒçŸ¥è¯†åº“æƒé‡ä»20%æå‡åˆ°64%
        optimized_history = self.history_optimizer.optimize_history(conversation_history)
        messages.extend(optimized_history)
        
        # è®°å½•ä¼˜åŒ–æ•ˆæœ
        if conversation_history:
            token_stats = self.history_optimizer.get_token_estimate(conversation_history)
            logger.info(
                f"ğŸ’° å¯¹è¯å†å²ä¼˜åŒ–: "
                f"{token_stats['original_count']}æ¡ â†’ {token_stats['optimized_count']}æ¡ | "
                f"Token: {token_stats['original_tokens']} â†’ {token_stats['optimized_tokens']} "
                f"(èŠ‚çœ{token_stats['save_percentage']}%)"
            )
        
        # 6. è°ƒç”¨LLMæœåŠ¡
        try:
            llm_service = create_llm_service(llm_model)
            response = llm_service.chat(messages=messages)
            
            # æ„å»ºçŸ¥è¯†æ¥æºåˆ—è¡¨ï¼ˆä¾›å‰ç«¯å±•ç¤ºï¼‰
            knowledge_sources = [
                {
                    'kb_name': r['kb_name'],
                    'content': r['content'][:200] + '...' if len(r['content']) > 200 else r['content'],
                    'similarity': round(r['similarity'], 4)
                }
                for r in knowledge_results
            ]
            
            return {
                'content': response.get('response', 'æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›ç­”ã€‚'),
                'knowledge_sources': knowledge_sources,
                'token_usage': response.get('token_usage', {
                    'prompt': 0,
                    'completion': 0,
                    'total': 0
                }),
                'model': llm_model.name
            }
        
        except Exception as e:
            logger.error(f"è°ƒç”¨LLMå¤±è´¥: {str(e)}", exc_info=True)
            return {
                'content': 'æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›ç­”ã€‚è¯·ç¨åå†è¯•æˆ–è”ç³»è€å¸ˆã€‚',
                'knowledge_sources': [],
                'token_usage': {'prompt': 0, 'completion': 0, 'total': 0},
                'model': llm_model.name
            }
    
    async def _get_recent_messages(
        self,
        conversation_id: int,
        limit: int = 10
    ) -> List[LearningAssistantMessage]:
        """è·å–æœ€è¿‘çš„æ¶ˆæ¯å†å²ï¼ˆæŒ‰æ—¶é—´å‡åºè¿”å›ï¼‰"""
        messages = self.db.query(LearningAssistantMessage).filter(
            LearningAssistantMessage.conversation_id == conversation_id
        ).order_by(
            LearningAssistantMessage.created_at.asc()  # å‡åºï¼Œæœ€æ—©çš„åœ¨å‰
        ).all()
        
        # å¦‚æœæ¶ˆæ¯æ•°é‡è¶…è¿‡é™åˆ¶ï¼Œåªè¿”å›æœ€è¿‘çš„limitæ¡
        if len(messages) > limit:
            return messages[-limit:]
        return messages
    
    async def _update_conversation_stats(self, conversation_id: int):
        """æ›´æ–°ä¼šè¯ç»Ÿè®¡ä¿¡æ¯"""
        conversation = self.db.query(LearningAssistantConversation).get(conversation_id)
        
        if not conversation:
            return
        
        # ç»Ÿè®¡æ¶ˆæ¯æ•°
        messages = self.db.query(LearningAssistantMessage).filter(
            LearningAssistantMessage.conversation_id == conversation_id
        ).all()
        
        conversation.message_count = len(messages)
        conversation.user_message_count = sum(1 for m in messages if m.role == 'user')
        conversation.ai_message_count = sum(1 for m in messages if m.role == 'assistant')
        conversation.last_message_at = datetime.now()
        
        # è®¡ç®—å¹³å‡å“åº”æ—¶é—´
        response_times = [m.response_time_ms for m in messages if m.response_time_ms]
        if response_times:
            conversation.avg_response_time = int(sum(response_times) / len(response_times))
        
        self.db.commit()
    
    async def _get_student_profile(self, user_id: int) -> Optional[StudentLearningProfile]:
        """è·å–å­¦ç”Ÿæ¡£æ¡ˆ"""
        profile = self.db.query(StudentLearningProfile).filter(
            StudentLearningProfile.user_id == user_id
        ).first()
        
        if not profile:
            # åˆ›å»ºé»˜è®¤æ¡£æ¡ˆ
            profile = StudentLearningProfile(
                user_id=user_id,
                total_conversations=0,
                total_messages=0,
                total_questions=0
            )
            self.db.add(profile)
            self.db.commit()
            self.db.refresh(profile)
        
        return profile
    
    async def _update_student_profile(
        self,
        user_id: int,
        message: str,
        context: Dict
    ):
        """æ›´æ–°å­¦ç”Ÿæ¡£æ¡ˆ"""
        profile = await self._get_student_profile(user_id)
        
        # æ›´æ–°ç»Ÿè®¡
        profile.total_messages += 1
        profile.total_questions += 1
        profile.last_active_at = datetime.now()
        
        # æ›´æ–°å­¦ä¹ è¯¾ç¨‹åˆ—è¡¨
        if context.get('course_uuid'):
            courses = profile.courses_learned or []
            course_ids = [c.get('uuid') for c in courses if isinstance(c, dict)]
            
            if context['course_uuid'] not in course_ids:
                courses.append({
                    'uuid': context['course_uuid'],
                    'name': context.get('course_name'),
                    'last_active': datetime.now().isoformat()
                })
                profile.courses_learned = courses
            
            profile.last_course_uuid = context['course_uuid']
        
        if context.get('unit_uuid'):
            profile.last_unit_uuid = context['unit_uuid']
        
        self.db.commit()
    
    async def _log_moderation(
        self,
        user_id: int,
        conversation_id: int,
        message_id: int,
        content_type: str,
        content: str,
        result: Dict
    ):
        """è®°å½•å®¡æ ¸æ—¥å¿—"""
        log = ContentModerationLog(
            user_id=user_id,
            conversation_id=conversation_id,
            message_id=message_id,
            content_type=content_type,
            original_content=content,
            status=result['status'],
            flags=result['flags'],
            risk_score=result['risk_score'],
            sensitive_words=result.get('sensitive_words_found'),
            moderation_service='local'
        )
        
        self.db.add(log)
        self.db.commit()
    
    async def _generate_conversation_title(
        self,
        user_message: str,
        ai_response: str
    ) -> Optional[str]:
        """
        æ ¹æ®é¦–æ¬¡å¯¹è¯å†…å®¹ï¼Œè®©AIç”Ÿæˆä¸€ä¸ªç®€çŸ­çš„ä¼šè¯æ ‡é¢˜
        
        Args:
            user_message: ç”¨æˆ·çš„é¦–æ¬¡æé—®
            ai_response: AIçš„é¦–æ¬¡å›å¤
            
        Returns:
            ç”Ÿæˆçš„æ ‡é¢˜ï¼ˆä¸è¶…è¿‡20å­—ï¼‰ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›None
        """
        try:
            logger.info(f"ğŸ·ï¸ å¼€å§‹ç”Ÿæˆä¼šè¯æ ‡é¢˜...")
            logger.debug(f"ç”¨æˆ·æ¶ˆæ¯: {user_message[:50]}...")
            
            # æ„é€ æ ‡é¢˜ç”Ÿæˆæç¤ºè¯ï¼ˆæ›´ç®€æ´æ˜ç¡®ï¼‰
            title_prompt = f"""è¯·ä¸ºä»¥ä¸‹å¯¹è¯ç”Ÿæˆä¸€ä¸ªç®€çŸ­æ ‡é¢˜ï¼ˆ5-15ä¸ªæ±‰å­—ï¼‰ã€‚

ç”¨æˆ·æé—®ï¼š{user_message[:100]}

è¦æ±‚ï¼š
1. åªè¿”å›æ ‡é¢˜ï¼Œä¸è¦ä»»ä½•å…¶ä»–å†…å®¹
2. ä¸è¦å¼•å·ã€æ ‡ç‚¹
3. ç›´æ¥æ¦‚æ‹¬ä¸»é¢˜

æ ‡é¢˜ï¼š"""

            messages = [
                {"role": "user", "content": title_prompt}
            ]
            
            # è°ƒç”¨LLMç”Ÿæˆæ ‡é¢˜ï¼ˆä½¿ç”¨é»˜è®¤æ¨¡å‹ï¼‰
            from app.models.llm_model import LLMModel
            llm_model = self.db.query(LLMModel).filter(
                LLMModel.is_default == 1,
                LLMModel.is_active == 1
            ).first()
            
            if not llm_model:
                logger.warning("âš ï¸ æœªæ‰¾åˆ°é»˜è®¤LLMæ¨¡å‹ï¼Œæ— æ³•ç”Ÿæˆæ ‡é¢˜")
                return None
            
            logger.info(f"ğŸ“¡ ä½¿ç”¨æ¨¡å‹: {llm_model.display_name} ({llm_model.name})")
            
            from app.services.llm_service import create_llm_service
            llm_service = create_llm_service(llm_model)
            
            response = llm_service.chat(messages)  # âœ… ç§»é™¤awaitï¼Œchatä¸æ˜¯å¼‚æ­¥æ–¹æ³•
            logger.debug(f"LLMè¿”å›: {response}")
            
            # å°è¯•å¤šä¸ªå¯èƒ½çš„é”®
            title = response.get('response') or response.get('content') or response.get('text') or ''
            title = title.strip()
            
            logger.info(f"ğŸ” åŸå§‹æ ‡é¢˜: '{title}'")
            
            # æ¸…ç†æ ‡é¢˜
            # 1. ç§»é™¤å¸¸è§çš„å‰ç¼€
            for prefix in ['æ ‡é¢˜ï¼š', 'æ ‡é¢˜:', 'ä¼šè¯æ ‡é¢˜ï¼š', 'ä¼šè¯æ ‡é¢˜:', 'æ ‡é¢˜ä¸ºï¼š', 'æ ‡é¢˜ä¸º:']:
                if title.startswith(prefix):
                    title = title[len(prefix):].strip()
            
            # 2. å»é™¤å¼•å·ã€æ¢è¡Œã€çœç•¥å·ç­‰
            title = title.replace('"', '').replace("'", '').replace('ã€Œ', '').replace('ã€', '')
            title = title.replace('\n', ' ').replace('\r', '').strip()
            title = title.rstrip('.')  # ç§»é™¤æœ«å°¾çš„å¥å·
            title = title.rstrip('ã€‚')  # ç§»é™¤æœ«å°¾çš„ä¸­æ–‡å¥å·
            title = title.rstrip('â€¦')  # ç§»é™¤æœ«å°¾çš„çœç•¥å·
            title = title.rstrip('...')  # ç§»é™¤æœ«å°¾çš„ä¸‰ä¸ªç‚¹
            title = title.strip()
            
            # 3. é™åˆ¶é•¿åº¦
            if len(title) > 20:
                title = title[:20]
            
            logger.info(f"âœ¨ æ¸…ç†åæ ‡é¢˜: '{title}'")
            
            # éªŒè¯æ ‡é¢˜æœ‰æ•ˆæ€§
            if not title or len(title) < 2:
                logger.warning(f"âš ï¸ æ ‡é¢˜æ— æ•ˆï¼ˆé•¿åº¦: {len(title)}ï¼‰")
                return None
            
            logger.info(f"âœ… æˆåŠŸç”Ÿæˆæ ‡é¢˜: '{title}'")
            return title
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆä¼šè¯æ ‡é¢˜æ—¶å‡ºé”™: {str(e)}", exc_info=True)
            return None

