#!/usr/bin/env python3
"""
æµ‹è¯•å­¦ä¹ åŠ©æ‰‹å¯¹è¯å†å²ä¼˜åŒ–å™¨
ç”¨äºéªŒè¯ä¼˜åŒ–æ•ˆæœå’ŒTokenèŠ‚çœ
"""
import sys
sys.path.append('..')

from app.services.learning_assistant_history_optimizer import ConversationHistoryOptimizer


def test_optimizer():
    """æµ‹è¯•ä¼˜åŒ–å™¨åŠŸèƒ½"""
    
    print("=" * 80)
    print("å­¦ä¹ åŠ©æ‰‹å¯¹è¯å†å²ä¼˜åŒ–å™¨æµ‹è¯•")
    print("=" * 80)
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = ConversationHistoryOptimizer(recent_user_questions=5)
    
    # æ¨¡æ‹Ÿ10è½®å¯¹è¯ï¼ˆ20æ¡æ¶ˆæ¯ï¼‰
    mock_messages = []
    
    for i in range(1, 11):
        # ç”¨æˆ·é—®é¢˜
        mock_messages.append({
            'role': 'user',
            'content': f'å­¦ç”Ÿç¬¬{i}ä¸ªé—®é¢˜ï¼š{"å¦‚ä½•ä½¿ç”¨Pythonï¼Ÿ" if i % 2 == 1 else "ESP32å¦‚ä½•çƒ§å½•å›ºä»¶ï¼Ÿ"}' + 'x' * 50
        })
        # AIå›å¤ï¼ˆé€šå¸¸æ›´é•¿ï¼‰
        mock_messages.append({
            'role': 'assistant',
            'content': f'AIå›å¤{i}ï¼š' + 'x' * 300
        })
    
    print(f"\nğŸ“Š åŸå§‹å¯¹è¯æ•°æ®:")
    print(f"   æ€»æ¶ˆæ¯æ•°: {len(mock_messages)}æ¡")
    print(f"   ç”¨æˆ·é—®é¢˜: {len([m for m in mock_messages if m['role'] == 'user'])}ä¸ª")
    print(f"   AIå›å¤: {len([m for m in mock_messages if m['role'] == 'assistant'])}ä¸ª")
    
    # ä¼˜åŒ–å†å²
    optimized = optimizer.optimize_history(mock_messages)
    
    print(f"\nâœ… ä¼˜åŒ–åæ•°æ®:")
    print(f"   ä¿ç•™æ¶ˆæ¯æ•°: {len(optimized)}æ¡")
    print(f"   å…¨éƒ¨ä¸ºç”¨æˆ·é—®é¢˜")
    
    # è®¡ç®—Token
    stats = optimizer.get_token_estimate(mock_messages)
    
    print(f"\nğŸ’° TokenèŠ‚çœç»Ÿè®¡:")
    print(f"   åŸå§‹Token: {stats['original_tokens']}")
    print(f"   ä¼˜åŒ–Token: {stats['optimized_tokens']}")
    print(f"   èŠ‚çœToken: {stats['saved_tokens']}")
    print(f"   èŠ‚çœæ¯”ä¾‹: {stats['save_percentage']}%")
    
    print(f"\nğŸ¯ ä¼˜åŒ–åçš„æ¶ˆæ¯å†…å®¹:")
    for i, msg in enumerate(optimized, 1):
        content_preview = msg['content'][:50] + '...' if len(msg['content']) > 50 else msg['content']
        print(f"   [{i}] {content_preview}")
    
    print("\n" + "=" * 80)
    print("âœ… æµ‹è¯•å®Œæˆï¼")
    print("=" * 80)


def test_different_configs():
    """æµ‹è¯•ä¸åŒé…ç½®çš„æ•ˆæœ"""
    
    print("\n" + "=" * 80)
    print("ä¸åŒé…ç½®å¯¹æ¯”æµ‹è¯•")
    print("=" * 80)
    
    # æ¨¡æ‹Ÿ20è½®å¯¹è¯
    mock_messages = []
    for i in range(1, 21):
        mock_messages.append({'role': 'user', 'content': 'x' * 80})
        mock_messages.append({'role': 'assistant', 'content': 'x' * 300})
    
    configs = [3, 5, 8, 10]
    
    print(f"\nå¯¹è¯æ€»é‡: {len(mock_messages)}æ¡æ¶ˆæ¯ï¼ˆ{len(mock_messages)//2}è½®å¯¹è¯ï¼‰\n")
    print(f"{'é…ç½®':<10} {'ä¼˜åŒ–å':<10} {'åŸå§‹Token':<15} {'ä¼˜åŒ–Token':<15} {'èŠ‚çœæ¯”ä¾‹'}")
    print("-" * 80)
    
    for config in configs:
        optimizer = ConversationHistoryOptimizer(recent_user_questions=config)
        stats = optimizer.get_token_estimate(mock_messages)
        
        print(f"{config}ä¸ªé—®é¢˜   {stats['optimized_count']}æ¡       "
              f"{stats['original_tokens']:<15} {stats['optimized_tokens']:<15} "
              f"{stats['save_percentage']}%")
    
    print("\nğŸ’¡ å»ºè®®: ")
    print("   - å¦‚æœå­¦ç”Ÿå¤šä¸ºç‹¬ç«‹é—®é¢˜ â†’ é€‰æ‹©3ä¸ªé—®é¢˜ï¼ˆæœ€çœTokenï¼‰")
    print("   - å¦‚æœéœ€è¦å¹³è¡¡è®°å¿†å’Œæˆæœ¬ â†’ é€‰æ‹©5ä¸ªé—®é¢˜ï¼ˆæ¨èï¼‰")
    print("   - å¦‚æœéœ€è¦æ›´é•¿çš„é—®é¢˜è„‰ç»œ â†’ é€‰æ‹©8ä¸ªé—®é¢˜")


if __name__ == "__main__":
    test_optimizer()
    test_different_configs()

